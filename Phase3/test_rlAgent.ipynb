{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a trained Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model, Sequential, model_from_json\n",
    "from keras.layers import Input, Dense, concatenate, Flatten, Conv2D, Permute, Reshape\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.callbacks import History \n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "\n",
    "import sys\n",
    "from PyQt5.QtGui import *\n",
    "from PyQt5.QtWidgets import *\n",
    "from PyQt5.QtCore import *\n",
    "from IPython import get_ipython\n",
    "\n",
    "from fittingEnv import *\n",
    "from interface import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matlab.engine\n",
    "eng = matlab.engine.start_matlab()\n",
    "\n",
    "def get_new_audio ():\n",
    "        path = 'PATH_TO_NOISY_SPEECH_FILES'\n",
    "        filename = glob.glob(os.path.join(path, '*.wav'))\n",
    "        seed = random.randint(0, (1<< 32) - 1)\n",
    "        random.seed(seed)\n",
    "        rnd_idx  = randint(0, np.asarray(filename).shape[0]-1)\n",
    "        rnd_idx = 100\n",
    "        speech_file  = filename[rnd_idx]\n",
    "        audio, fs = librosa.load(speech_file)\n",
    "        fsTarget = int(16000.0)\n",
    "        if len(audio.shape) > 1:\n",
    "            audio = audio[:,0]\n",
    "        if fs != fsTarget:\n",
    "            audio = librosa.resample(audio, fs, fsTarget)\n",
    "        \n",
    "        return audio, fsTarget\n",
    "    \n",
    "def next_observation(audio, fs=16000, overlap_size=int(0.01*16000), frame_size=int(0.02*16000), nFilt=80, nFrames  = 3 ):\n",
    "\n",
    "\n",
    "    ## Compute mel spectrogram features from uncompressed audio\n",
    "    audio_len  = int(fs * 2.5) # only 2.5 seconds audio for agent input\n",
    "    audio_seg  = audio[:audio_len]\n",
    "    MFSC_feat_audio = librosa.feature.melspectrogram(y= audio_seg, sr=fs, hop_length=overlap_size, \n",
    "                                                     win_length=frame_size, window='hann', n_mels=nFilt, fmax=8000)\n",
    "    mellog = librosa.power_to_db(MFSC_feat_audio, ref=np.max)\n",
    "    # Normalization each row to [0,1]:\n",
    "    for i in range(nFilt):\n",
    "        arr = mellog[i,:]\n",
    "        arr = arr - np.min(arr)\n",
    "        safe_max = np.max(np.abs(arr))\n",
    "        if safe_max==0:\n",
    "            safe_max = 1\n",
    "        arr = arr / safe_max\n",
    "        mellog[i,:] = arr\n",
    "\n",
    "    ## Create Mel spectrogram images\n",
    "    # nFrames  = int(np.floor(MFSC_features.shape[1]/self.nFilt))\n",
    "    mfsc_img_audio = np.zeros((nFilt, nFilt, nFrames))\n",
    "    k = 0\n",
    "    for i in range(nFrames):\n",
    "        mfsc_img_audio[:,:,i] = mellog[:,k:k+nFilt]\n",
    "        k = k + nFilt\n",
    "\n",
    "    # Update system states\n",
    "    obs_agent = mfsc_img_audio ## TODO2 : include newCR or action as well in the next obs.\n",
    "\n",
    "    return obs_agent, mellog\n",
    "\n",
    "\n",
    "def apply_compression (audio , newCR, INIT_softG, fs=16000):\n",
    "\n",
    "    def npArray2Matlab (arr):\n",
    "        return matlab.double(arr.tolist()) # casting a as list\n",
    "\n",
    "    audio_len  = int(fs * 2.5) # only 2.5 seconds audio for agent input\n",
    "    audio_seg  = audio[:audio_len]\n",
    "    out_DRC = eng.perform_compression (npArray2Matlab(audio_seg), npArray2Matlab(newCR), fs , npArray2Matlab(INIT_softG), nargout=1 )\n",
    "    out_DRC = np.array(out_DRC)\n",
    "\n",
    "    # normalize the compressued audio (amplitude compensation)\n",
    "    audio_max1 = np.max(np.abs(out_DRC))\n",
    "    if audio_max1 == 0:\n",
    "        audio_max1 = 1\n",
    "    out_DRC = out_DRC / audio_max1\n",
    "    out_DRC = out_DRC.reshape(-1)\n",
    "\n",
    "    return out_DRC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained RL agent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"rl_model.h5\")\n",
    "print(\"Loaded model from disk\")     \n",
    "model._make_predict_function() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect hearing perefrences (Visit 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window allocation for human interface :\n",
    "if QApplication.instance() is None:\n",
    "    app = QApplication(sys.argv)\n",
    "%gui qt5 ## enable PyQt5 event loop integration for .pynb files\n",
    "#get_ipython().run_line_magic('gui', 'qt5 ## enable PyQt5 event loop integration') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INITIAL_CRs   = np.array ([1.1, 1.2, 1.3, 1.2, 1.4]) # Define 2D matrix numpy array\n",
    "INITIAL_softG = np.array ([6.0, 11.0, 20.0, 23.0, 20.0]) # Define 2D matrix numpy array\n",
    "\n",
    "env = fittingEnv()\n",
    "\n",
    "preference = -1 # initialize to none\n",
    "adjustCR = [1,1,1,1,1] # only for the first time\n",
    "\n",
    "for i in range(30):\n",
    "\n",
    "    while True:\n",
    "\n",
    "        audio,fs = get_new_audio ()\n",
    "        obs_agent, _ = next_observation(audio, fs)\n",
    "\n",
    "        adjustCR = np.reshape(adjustCR, (5,))\n",
    "\n",
    "        # Agent obs is # mel-spectrogram images of unprocessed audio + prev actions\n",
    "        obs1 = np.expand_dims(obs_agent, axis=0)\n",
    "        obs2 = np.expand_dims(adjustCR, axis=0)\n",
    "        #print(obs1.shape)\n",
    "        #print(obs2.shape)\n",
    "\n",
    "        pred_agent = model.predict([obs1 , obs2]) # gets predicted action\n",
    "        action = np.argmax(pred_agent)\n",
    "\n",
    "        obs_agent, obs_RePrd, audio, adjustCR, _, done, info = env.step(action)\n",
    "        print(adjustCR)\n",
    "\n",
    "        newCR   = np.multiply(np.reshape(INITIAL_CRs, (5,)), np.reshape(adjustCR, (5,)) )\n",
    "        print(\"newCR = \", newCR) \n",
    "\n",
    "        out_DRC_rl  = apply_compression (audio , newCR, INITIAL_softG, fs)\n",
    "        audio_max1 = np.max(np.abs(out_DRC_rl))\n",
    "        if audio_max1 == 0:\n",
    "            audio_max1 = 1\n",
    "        out_DRC_rl = out_DRC_rl / audio_max1\n",
    "        \n",
    "        out_DRC_DSL = apply_compression (audio , INITIAL_CRs, INITIAL_softG, fs)\n",
    "        audio_max2 = np.max(np.abs(out_DRC_DSL))\n",
    "        if audio_max2 == 0:\n",
    "            audio_max2 = 1\n",
    "        out_DRC_DSL = out_DRC_DSL / audio_max2\n",
    "\n",
    "        idx = randint(1,2)\n",
    "        print(idx)\n",
    "        if idx == 1:\n",
    "            audio1 = out_DRC_DSL\n",
    "            audio2 = out_DRC_rl\n",
    "        else:\n",
    "            audio1 = out_DRC_rl\n",
    "            audio2 = out_DRC_DSL\n",
    "        #########\n",
    "        data, fs2 = sf.read('beep-01a.wav', dtype='float32')  \n",
    "        sd.play(0.1*data, fs2)\n",
    "        status = sd.wait()  # Wait until file is done playing\n",
    "        #########\n",
    "        print(\"Please choose the preferred audio, 1 or 2. Press both for neutral.\")\n",
    "        win = AudioPlayer()\n",
    "        win.show()\n",
    "        win.set_audio(audio1, fs, 0)\n",
    "        win.set_audio(audio2, fs, 1)\n",
    "        key = win.get_response()\n",
    "        win.close()\n",
    "        print(\"preference is = \", key)\n",
    "\n",
    "        if key == 0:\n",
    "            preference = 0\n",
    "        elif key == 1:\n",
    "            preference = 1\n",
    "        elif key == 2:\n",
    "            preference = 2\n",
    "\n",
    "        # Open a file to have users preferences\n",
    "        f = open(\"test_results.txt\", \"a\")\n",
    "        if preference == 0:\n",
    "            if idx ==1:\n",
    "                pref_save = [1.0,0.0] \n",
    "            else:\n",
    "                pref_save = [0.0,1.0] \n",
    "        elif preference == 1:\n",
    "            if idx ==1:\n",
    "                pref_save = [0.0,1.0] \n",
    "            else:\n",
    "                pref_save = [1.0,0.0]\n",
    "        else:\n",
    "            pref_save = [0.5,0.5]   \n",
    "\n",
    "        print('CR1 = ', np.reshape(INITIAL_CRs, (5,)), file=f) # save the preference into .txt file\n",
    "        print('CR2 = ', newCR, file=f) # save the preference into .txt file\n",
    "        print('preference = ', pref_save, file=f) # save the preference into .txt file\n",
    "        print('====================================', file=f)\n",
    "        f.close()\n",
    "\n",
    "        # End of saving preferences\n",
    "        if preference != -1:\n",
    "            break\n",
    "\n",
    "\n",
    "print(\" ******** End of session! :)  ********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
